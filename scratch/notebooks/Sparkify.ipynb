{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorSlicer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Sparkify\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"user_data_agg.json\"\n",
    "df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for data processing by Spark\n",
    "\n",
    "categoricalColumns = [\"gender\", \"region\"]\n",
    "numericCols = ['avg_mins_on_date',\n",
    " 'avg_nextsong_per_day',\n",
    " 'avg_nextsong_per_month',\n",
    " 'avg_submit_downgrade_per_day',\n",
    " 'avg_submit_downgrade_per_month',\n",
    " 'avg_submit_upgrade_per_day',\n",
    " 'avg_submit_upgrade_per_month',\n",
    " 'avg_sum_about_per_day',\n",
    " 'avg_sum_about_per_month',\n",
    " 'avg_sum_add_friend_per_day',\n",
    " 'avg_sum_add_friend_per_month',\n",
    " 'avg_sum_add_playlist_per_day',\n",
    " 'avg_sum_add_playlist_per_month',\n",
    " 'avg_sum_downgrade_per_day',\n",
    " 'avg_sum_downgrade_per_month',\n",
    " 'avg_sum_error_per_day',\n",
    " 'avg_sum_error_per_month',\n",
    " 'avg_sum_help_per_day',\n",
    " 'avg_sum_help_per_month',\n",
    " 'avg_sum_home_month',\n",
    " 'avg_sum_home_per_day',\n",
    " 'avg_sum_logout_per_day',\n",
    " 'avg_sum_logout_per_month',\n",
    " 'avg_sum_roll_advert_per_day',\n",
    " 'avg_sum_roll_advert_per_month',\n",
    " 'avg_sum_save_settings_per_day',\n",
    " 'avg_sum_save_settings_per_month',\n",
    " 'avg_sum_settings_per_day',\n",
    " 'avg_sum_settings_per_month',\n",
    " 'avg_sum_thumbs_down_per_day',\n",
    " 'avg_sum_thumbs_down_per_month',\n",
    " 'avg_sum_thumbs_up_per_day',\n",
    " 'avg_sum_thumbs_up_per_month',\n",
    " 'avg_sum_upgrade_per_day',\n",
    " 'avg_sum_upgrade_per_month',\n",
    " 'avg_visits_next_songs',\n",
    " 'paid_pct',\n",
    " 'pct_total_pos_engagement',\n",
    "              ]\n",
    "stages = [] # stages in Pipeline\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCol=stringIndexer.getOutputCol(), outputCol=categoricalCol + \"classVec\")\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol=\"churned\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"vectorized_features\")\n",
    "stages += [assembler]\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"vectorized_features\", outputCol=\"features\")\n",
    "stages += [scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test. Use pipeline to process the data for analysis.\n",
    "\n",
    "cols = numericCols + categoricalColumns + ['churned']\n",
    "train, test = df[cols].randomSplit([0.8, 0.2], seed=1973)\n",
    "\n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(train)\n",
    "train_df = pipelineModel.transform(train)\n",
    "\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "train_df = train_df.select(selectedCols)\n",
    "\n",
    "test_df = pipelineModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(predictions):\n",
    "    \"\"\"Calculate metrics\"\"\"\n",
    "    selected = predictions.toPandas()\n",
    "    f1 = f1_score(selected.label, selected.prediction)\n",
    "    recall = recall_score(selected.label, selected.prediction)\n",
    "    precision = precision_score(selected.label, selected.prediction)\n",
    "\n",
    "    area_under_PR = evaluator.evaluate(predictions)\n",
    "    \n",
    "    return f1, recall, precision, area_under_PR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Random Forest model for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort feature importances [https://people.stat.sc.edu/haigang/improvement.html]. These will be used to select the more important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderPR\") \n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=1973)\n",
    "rf_model = rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_list = pd.Series(rf_model.featureImportances.values)\n",
    "sorted_imp = importance_list.sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the feature importance values to select features for the training set. Select a cut-off value that maximizes the area under the precision-recall curve for the modified training sets. Depending on the cut-off chosen each training set will have different number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_offs = np.arange(0.010, 0.080, 0.005) \n",
    " \n",
    "train_pr = []\n",
    "\n",
    "for c in cut_offs:\n",
    "\n",
    "    kept = list((sorted_imp[sorted_imp > c]).index)\n",
    "    vector_slicer = VectorSlicer(inputCol= \"features\", indices= kept, outputCol=\"feature_subset\")\n",
    "    with_selected_feature = vector_slicer.transform(train_df)\n",
    "\n",
    "    rf_modified = RandomForestClassifier(featuresCol=\"feature_subset\", seed=1973)\n",
    "    \n",
    "    rf_model = rf_modified.fit(with_selected_feature)\n",
    "    predictions_modified = rf_model.transform(with_selected_feature)\n",
    "    \n",
    "    evaluator_modified = BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\n",
    "    train_pr.append(evaluator_modified.evaluate(predictions_modified))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f465e3e2ac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot areaUnderPR vs cut-offs\n",
    "plt.plot(cut_offs, train_pr, alpha=0.5, color='r', label=\"pr\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables selected: 31\n"
     ]
    }
   ],
   "source": [
    "#Index of cut-off at which area under PR is maximized\n",
    "max_idx = np.where((np.round(train_pr, 10) == (np.round(max(train_pr), 10))))\n",
    "print(f\"Number of variables selected: {len(sorted_imp[sorted_imp > cut_offs[max_idx[0][0]]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep reduced set of features in train, test\n",
    "kept = list((sorted_imp[sorted_imp > cut_offs[max_idx[0][0]]]).index)\n",
    "vector_slicer = VectorSlicer(inputCol= \"features\", indices= kept, outputCol=\"feature_subset\")\n",
    "train_df_reduced = vector_slicer.transform(train_df)\n",
    "\n",
    "test_df_reduced = vector_slicer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set area under PR as the metric. \n",
    "evaluator_modified = BinaryClassificationEvaluator(metricName=\"areaUnderPR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the random forest model with reduced set of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a random forests model with default settings\n",
    "rf = RandomForestClassifier(featuresCol=\"feature_subset\", seed=1973)\n",
    "rf_default = rf.fit(train_df_reduced)\n",
    "\n",
    "# Make predictions on all train data\n",
    "predictions = rf_default.transform(train_df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature subset strategy: auto\n",
      "Feature subsampling rate: 1.0\n",
      "Number of trees: 20\n",
      "Max depth: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature subset strategy: {rf_default._java_obj.getFeatureSubsetStrategy()}\")\n",
    "print(f\"Feature subsampling rate: {rf_default._java_obj.getSubsamplingRate()}\")\n",
    "print(f\"Number of trees: {rf_default._java_obj.getNumTrees()}\")\n",
    "print(f\"Max depth: {rf_default._java_obj.getMaxDepth()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.607, Recall: 0.436, Precision: 1.000, Area under PR: 0.903\n"
     ]
    }
   ],
   "source": [
    "f1, recall, precision, area_under_PR = get_metrics(predictions)\n",
    "print(f'F1-Score: {f1:.3f}, Recall: {recall:.3f}, Precision: {precision:.3f}, Area under PR: {area_under_PR:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search: \n",
    "Use grid search with cross-validation to find best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_modified = RandomForestClassifier(featuresCol=\"feature_subset\", seed=1973)\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf_modified.featureSubsetStrategy, ['4', '6', '8'])\n",
    "             .addGrid(rf_modified.subsamplingRate, [0.8, 1])\n",
    "             .addGrid(rf_modified.maxDepth, [5, 8])\n",
    "             .build())\n",
    "\n",
    "cv = CrossValidator(estimator=rf_modified, estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator_modified, numFolds=5, seed=1973)\n",
    "cv_Model = cv.fit(train_df_reduced)\n",
    "\n",
    "best_model = cv_Model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fss = best_model._java_obj.getFeatureSubsetStrategy()\n",
    "ssr = best_model._java_obj.getSubsamplingRate()\n",
    "num_trees = best_model._java_obj.getNumTrees()\n",
    "max_depth = best_model._java_obj.getMaxDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the best model on the entire training set\n",
    "\n",
    "rf_complete = RandomForestClassifier(featuresCol=\"feature_subset\", subsamplingRate=ssr, maxDepth=max_depth, \n",
    "                                     featureSubsetStrategy=fss, seed=1973)\n",
    "rf_complete_model = rf_complete.fit(train_df_reduced)\n",
    "\n",
    "# Make predictions on all train data\n",
    "predictions = rf_complete_model.transform(train_df_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.818, Recall: 0.692, Precision: 1.000, Area under PR: 0.998\n"
     ]
    }
   ],
   "source": [
    "f1, recall, precision, area_under_PR = get_metrics(predictions)\n",
    "print(f'F1-Score: {f1:.3f}, Recall: {recall:.3f}, Precision: {precision:.3f}, Area under PR: {area_under_PR:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create weight variable to address the class imbalance in the target\n",
    "dataset_size = float(train_df.select(\"label\").count())\n",
    "numPositives = train_df.select(\"label\").where('label == 1').count()\n",
    "per_ones = (float(numPositives)/float(dataset_size))*100\n",
    "numNegatives = float(dataset_size - numPositives)\n",
    "BalancingRatio = numNegatives/dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ones are 78\n",
      "Percentage of ones are 22.413793103448278\n",
      "Balancing ratio 0.7758620689655172\n"
     ]
    }
   ],
   "source": [
    "print('The number of ones are {}'.format(numPositives))\n",
    "print('Percentage of ones are {}'.format(per_ones))\n",
    "print('Balancing ratio {}'.format(BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the weights variable to the train set\n",
    "train_with_weights = train_df_reduced.withColumn(\"classWeights\", \n",
    "                                                               when(train_df.label == 1, \n",
    "                                                                    BalancingRatio).otherwise(1 - BalancingRatio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a logistic regression model with the reduced set of variables. Use grid search with cross-validation to find best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"feature_subset\", weightCol=\"classWeights\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "            .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "            .addGrid(lr.maxIter, [10, 15])\n",
    "            .addGrid(lr.threshold, [0.4, 0.5, 0.6])\n",
    "            .build())\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator_modified, numFolds=5, seed=1973)\n",
    "cv_Model = cv.fit(train_with_weights)\n",
    "best_model = cv_Model.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enp = best_model._java_obj.getElasticNetParam()\n",
    "rp = best_model._java_obj.getRegParam()\n",
    "max_iter = best_model._java_obj.getMaxIter()\n",
    "threshold = best_model._java_obj.getThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model with the best parameters on the entire training set\n",
    "lr_complete = LogisticRegression(labelCol=\"label\", featuresCol=\"feature_subset\", weightCol=\"classWeights\",\n",
    "                       threshold=threshold, elasticNetParam=enp, regParam=rp, maxIter=max_iter)\n",
    "lr_complete_model = lr_complete.fit(train_with_weights)\n",
    "\n",
    "# Make predictions on all train data\n",
    "predictions = lr_complete_model.transform(train_with_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.401, Recall: 0.949, Precision: 0.254, Area under PR: 0.563\n"
     ]
    }
   ],
   "source": [
    "f1, recall, precision, area_under_PR = get_metrics(predictions)\n",
    "print(f'F1-Score: {f1:.3f}, Recall: {recall:.3f}, Precision: {precision:.3f}, Area under PR: {area_under_PR:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the decision tree model with reduced set of variables. Use grid search with cross-validation to find best model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='label', featuresCol='feature_subset')\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [4, 5, 6])\n",
    "             .addGrid(dt.maxBins, [20, 40, 60])\n",
    "             .build())\n",
    "\n",
    "cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator_modified, numFolds=5, seed=1973)\n",
    "cv_Model = cv.fit(train_df_reduced)\n",
    "\n",
    "best_model = cv_Model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = best_model._java_obj.getMaxDepth()\n",
    "max_bins = best_model._java_obj.getMaxBins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model with the best parameters on the entire training set\n",
    "dt_complete = DecisionTreeClassifier(labelCol='label', featuresCol='feature_subset', seed=1973,\n",
    "                                     maxDepth=max_depth, maxBins=max_bins)\n",
    "dt_complete_model = dt_complete.fit(train_df_reduced)\n",
    "\n",
    "# Make predictions on all train data\n",
    "predictions = dt_complete_model.transform(train_df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.791, Recall: 0.654, Precision: 1.000, Area under PR: 0.321\n"
     ]
    }
   ],
   "source": [
    "f1, recall, precision, area_under_PR = get_metrics(predictions)\n",
    "print(f'F1-Score: {f1:.3f}, Recall: {recall:.3f}, Precision: {precision:.3f}, Area under PR: {area_under_PR:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit best model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_modified = BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = lr_complete_model.transform(test_df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.340, Recall: 0.900, Precision: 0.209, Area under PR: 0.378\n"
     ]
    }
   ],
   "source": [
    "#lr\n",
    "f1, recall, precision, area_under_PR = get_metrics(predictions)\n",
    "print(f'F1-Score: {f1:.3f}, Recall: {recall:.3f}, Precision: {precision:.3f}, Area under PR: {area_under_PR:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the logistic model despite it having a lower area under pr value compared to the random forest model. The latter appears to be overfitting. We still get a rather poor f1-score but a high recall. We are able to capture most of the users that churned but at the cost of having false positives which lowers precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- https://people.stat.sc.edu/haigang/improvement.html\n",
    "- https://datascience.stackexchange.com/questions/13960/how-to-choose-a-classifier-after-cross-validation\n",
    "- https://stats.stackexchange.com/questions/2306/feature-selection-for-final-model-when-performing-cross-validation-in-machine\n",
    "- https://medium.com/swlh/logistic-regression-with-pyspark-60295d41221\n",
    "- https://towardsdatascience.com/predict-customer-churn-using-pyspark-machine-learning-519e866449b5\n",
    "- https://docs.databricks.com/_static/notebooks/binary-classification.html\n",
    "- https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/\n",
    "- https://stackoverflow.com/questions/53528481/feature-selection-in-pyspark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
